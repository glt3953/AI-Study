一条新的这个工具链呢? 我先从这个现在的工具链来说 从开发模型开发角度上来说 可能还好 因为现在其实跟research现在的习惯有很多是是是对应的吧 但是从部署的角度上来说 现在工具链确实还是有一些问题的 特别是如果要function 我function 我有必要去 特别是针对终端场景的环境 我有必要去完全的理解这个模型里面每一层在做什么 我需要 我有必要去配置 就是看的整个一个很大的一个PyTorch也好 还是TensorFlow也好 在这个框架下面 重新去装一个完整的Trinning job吧 似乎不用这个东西可以变得更简单 那有现在有一些开源的方案是说我给你wrap到GUI web GUI里面呢 在GUI里面就做这件事情 那他也不一定是最终解决方案 那针对各个场景的function是不是应该有更简单的工具 更简单的服务 呃 我们的答案是是 那如果是的话我们要做什么 这是我们要探正在探索的事情 那你现在看到这一块工具链上有哪一些 呃 你觉得可能的通点啊 嗯 我们现在最直接的其实是API 然后API现在有不同层次的API 这其实是工具链的一部分 再往后的 我们只能说我现在我们在探索 因为这确实是一个作为开源公司 然后作为我们现在正在做的这种 呃 我们做房地是model的直接的下下一个环节 可能是比较重要的一件事情 呃 我们我只能回答说我们在探索 但没有一个具体的答案 我可以说一下这个 我们之前的应用就是那种中型的比较小的模型 这是一方面 另外一方面我大模型的应用可能刚刚开始吧 呃 所以所以呃 所以我可能有一些猜测或者说有一些推测 嗯 小模型的话 嗯 它它会游戏在edge这块 比如IoT车载啊 它一直是属于compute 它一直属于这个资源受限的这么一个环境 那就主要的大部分的不是compute的这个限制 而是memory的限制 因此呃 你在这个你的模型在漏的这个你的数据的时候 你总会hit memory wall 一般来说 算力并不是可能是一个更小的问题 那结论就最后怎么去解决这个矛盾 会有很多的这个 其实有已经开始有很多的这个公司在在试图解决 试图解决这一类的问题 比如说你 你可以有很多办法吗 比如说你可以把你的模型裁剪一下 你可以把你的这个你可以把你的这个数据类型改一下 你把你是IP IP16你就改成int8 你是int8还可以改成int4 然后你再做实验看看哦 我从IP16到int8 我的这个quality ml quality下降了多少 int8到int4quality下降了多少 这些quality下降是否能够承受 那另外就是再往下还有一些同 还有一些我们看到一些人就在做什么呢 在做编译器的优化 我在编译器上 我比如说我有一个 我会有一个比较比较好的编译器或编译器的库 那就编译器的库把不同的计算资源 通常我的很多芯片里面既有CPU GPU对吧 那然后还有这个可能还有DSP或者是有NPU 他们的编译器是不一样 他们programming language和programming mode也是不一样的 有的用openCL 有的用黑light 有的用sync intrinsic 那你怎么去统一它 然后在IP之间他们的这个你怎么统一IP之间 一样的run time overhead 你怎么统一他们之间的这个这个memory to memory的这个overhead 你怎么去优化这些东西 很多公司在做这些事情 那其实去年我跟我们的朋友们投了一家公司叫OMNI ML 我们觉得是比较好的 他做了两件事情 他在上层在模型的这个层面呢 他根据你的要求 相当于做这个hardware specific的pruning 然后在下层呢 他会去做针对你不同的这个嵌入式的系统 比如说你是高通的芯片还是NVIDIA的芯片 他根据他的这个下面编译器的特点 那高通的芯片他用的是LVM的这个编译器嘛 那VM用CUDA 那对于不同的这个编译器你会使用什么 你会你应该你应该引用什么样的库 这些东西他们也做了一些自动化的处理 那最后我听说他们的这个业务成长还是很快的 这从侧面也说明说 也说明这个需求一直存在的 那其实大厂也有在做这些事情 你比如说Google的AutoML AutoML虽然早期来说是更多的有这样的有更多的这个model architecture search的这个功能 他更多的是面对ML quality 就是你希望得到质量更好的这个模型 但是同时你在知道什么质量好 什么质量不好的模型的时候 你也会知道他们的模型的尺寸和他们的这个 和他们相关的Latency Performance会是怎么样子的 那这个时候其实你也可以 你也可以做 他也可以变相的做这个model acceleration 对吧那AWS出了一个产品叫做SageMaker Neo SageMaker Neo做的工作也是类似的 就是他虽然做的不怎么厉害 但是他在VDA上做的还可以 他等于是他试图他做的和OMML有一些类似 他试图统一所有现有的嵌入式系统做inference嵌入式系统的这个不同的compiler 然后比较这些compiler之上这些芯片厂商的这个这个这个compiling的这个这个库 然后说我搞一套抽象化的这个compiler出来 然后你你只要你就像选EC2一样 你选择了相应的这个硬件 我就给你做相应的这个加速 inference的加速和优化 但是从现在看来的话 他上面现在他主要的官方的合作伙伴是有这个 安霸和这个安霸Intel和NVIDIA可能还有高通 但是我从他的客户的角度来看 我采访访谈他一些客户 大概来说的话 只有NVIDIA平台上的客户是基本满意的 但是你话说回来 其实CUDA本身自己的编译器做这些工作已经是很不错了 所以我觉得SageMaker Edge Neo可能需要再进一步的 它可能要再进一步的迭代 但起码从AWS来角度来讲 它已经重视到了这个问题 那我现在说的都是这种中型的模型 就比如说Burke或者是ResNet 这种类型的上一代的这种模型 那大模型怎么变 我觉得这是我 我也没因为大模型这个东西GDP3.0 Stable Diffusion刚刚出来 其实没有 我认为我们的思考和也是不充分的 数据也是不充分的 我只能做一些发表一些观点吧 首先我觉得大模型的training肯定是需要优化的 未来我们可以想象GDP5 假设GDP5GDP6一次training 按照现在的这个训练方式来讲的话 可能要上亿了 上亿美金一定哪怕是像微软这样的企业 对它来说也不是一个很好的选择 而且你看现在GDP3 我看到GDP 这个GDP3.5 我自己的感觉就是我用了两个月 我感觉它前前后后可能 我能感受到的这个更新 也就是它的retraining可能就有三次 那你可以想象如果GDP6两个月training三次 那六个月training18次 那18次一次的retraining是一亿美金的话 那不就是一年就18亿美金 这个cap ex也不是这样的大厂能够很轻易的承受的 所以我认为一定会在training的toolchain上面 这个有所突破 那我觉得这个上面反而是小公司的一个优势 我最近也在看一些sub 我认为有一些sub 甚至我自己投的sub 里面有机会解决这个问题 就是把你的training的cost 把你这个大模型的training cost 一下给你降低个五倍 我认为training的cost cost saving应该是会很重要的 其实在这里面我稍微插一句 就是刚才雪芝说的这个多模态 multimodal input 实际上今天多模态对于language model 来说是一个新事物 对我们VCB的人来说反而是个老事情 就是multimodal input 我们到2022年就开始 已经在我自己的工作应用上用上了 因为不是因为我们先进 而是因为我们实在没办法了 我自己做的工作可能还有一些不能说 但是我可以说一下 就是在2020年的时候 我们在线下meetup跟Andrej Kapasi有过一个访谈 Andrej Kapasi当时还是Tesla的job driving head 然后他当时AI day完了以后 我们当时的感觉他没有讲透 但是我们的感觉是说 他一定用了multimodal input based multitask learning 也就是说后来我们去问他 当然他也可能也没有直接证明回来 但是我们非常确定 他的input里面一定有 肯定是有这个有他的这个视频 就是video 然后有他的关键帧 因为所有的vision 这种self-driven vision model 一定会有关键帧的input 然后第三个有IMU 那IMU的input是一个IMU就是输出的是quaternion 中文叫做可能叫四元素吧 这quaternion它是一个向量 然后它是以比如说1000帧2000帧这种数据来输的 就像刚才雪子说的 这个IMU的输出和关键帧的IMU的格式 关键帧的格式和这个video的格式都是不一样的 那这个时候在2021年的时候 如果大家注意到的话 你会发现2020年到2021年的FSD 很多的用户 早期用户的反馈是他的gain提高了很多 但在那个时候你会发现有两个很值得注意 很值得玩味的点 第一个是他慢慢的取消了 他的这个雷达 他的radar 然后第二件事情是他坚决不用lidar 很多人觉得Elon Musk脑子脑歪是不是被驴踢了 但实际上他并没有丧失理智 他其实很多的时候是考虑这个 exactly考虑刚才雪子说的这个问题 就是说如果我再加个radar 再加一个lidar再加个激光雷达 那这些数据进入我的ML model 我把这两个multi model的input跟进去以后 我又没有gain了 那这个我们可以想一下 首先第一他们早期的这个gain是不完整的 尤其是radar radar他们会他们明确就提在一次 Q&A上明确提了我radar对我的data pipeline 来说是非常非常痛苦的 但是对我的train training是没有gain的 然后lidar的话我的integration 我的data pipeline integration的cost会更高 然后有没有gain我不知道 那我现在发现但是我现在发现我的关键帧 加上我的video再加上我的MU 我的gain在我只要加到我的模型 我后面的gain是没有 gain还line of sight还没有cap 那我还不如先把这三种mode先给它挖掘到头 然后再去考虑要不要加lidar 其实我觉得这是他的这个 这是他为什么不加lidar和取消radar的 这个一个很重要的原因 所以这其实是跟多模态是有关系的 所以我可以理解 其实这个是我们应用多模态的时候 需要考虑的一个tradeoff是吧 就是我把更多的这个input加进来 它肯定是增加我的这个复杂程度 然后它最后的这个Ri可能在不同的场景 它是不一样的 不是在所有场景都多么态势好 对啊那你就这个里面就很有一个很有意思的事情 美国某一线L4的这个自动驾驶的工那个大厂 它的这个它的这个模型 现在每一次的模型训练 它里面是有有雷达也有激光雷达的 它一次模型训练模型训练的成本 是在900万到1300万美金之间 那它的那我我我 然后在这里面呢 在这里面这个多模态 我还我们还不提多模态的后面的训练了 就提多模态前面 就是你把这些数据光做一天 可能就要花到上百万美金 你想想这是什么概念 那那这个那这个其实你的多模态的选择 哪些模态对你是对你是有gain的 是你值得投入的 在什么时间段是值得投入的 我觉得这个是一个很有很有意思的一个问题 对对对CV来说 我们已经探过这些雷了 我想的话对这个LOM来说的话 很可能当然我也不太懂LOM 但是但是对LOM来说 你怎么选择这个输入的模态 它这些模态是不是每个模态都有很明显的gain 那这些可能也是值得考虑的问题 并不一定每个模态都是有都是有gain的 对对我想也许等到这个GPT-4出来 然后或者这个这个多模态这个模式出来了以后 我们可以有一次follow up的这个讨论 好那我们这个最后最后一个问题 其实也是更落地的一个一个问题 你们觉得你作为一个产品经理 可能在设计和思考产品的时候 应该考虑需要考虑哪一些 应该怎么样更好的能够把这个AI融入到这个产品里 对我觉得我虽然我可能恰好做了一些 不少产品它的这个solution里面用了使用AI technology 但是对我来说我还是更关心我作为PM 我更关心的是problem space 就是有什么样重要的problem 比这个东西比AI是不是适合 做一个好的solution这个更重要 当我觉得有一些我我首先会关注 因为我其实作为一个AI PM 首先是个PM所以我关注重要的问题 然后这个问题如果足够重要的话 我再来看它的solution是什么 这里面不一定需要有 我觉得不一定需要有很多AI的工作 或者AI的这个成分在里面 我记得我自己第一个产品 我自己第一个ML的solution 就是很多年前做这个quality inspection 10年前了 那我们直接就用的是SDM SDM是一个什么60年40年老的一个 一个一个machine learning technique 但是它能够它能给我 给我的公司一年节省大约可能五六千万美金的成本吧 你帮他们来一部五六千万美金 实际上是一个很 其实我觉得是一个很好的产品 这个不咱不一定需要用LM来做一样的事情 SDM可能就够了 所以关注problem space是我最重要的 是我觉得是首要的 谢谢大家