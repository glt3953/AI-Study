那包括各种部署 我们包括各个小的场景 如果想做function等等 在这样的一个参数量下面 任何的操作都会是一个很大的一个 对于想要做这样做的人来说都会是一个很大的压力 那在不同的场景下面 从产品的角度上来说 大家确实会比较期待能看到一些更多的 嗯 更轻量的模型 可能几十B 是不是能够更多 是不是能够在现有的架构结构下面去做征流 是不是能够 嗯 探索出更轻量的解决方案 更轻量的解决方案 在现有的 即便是我们仍然需要它去看大量的这个training tokens 但最终能够负责于 deployment的部分应该是足够轻量的 这样这个应用场景才能更好的成长起来 否则会有一个比较大的一个成本压力 嗯 我觉得这个角度特别好 到时候我们可以就就是这个大模型也好 还有 在这个不论是training还是推理 在实际应用中落地的一些 一些一些挑战和一些最佳时间 如果问我的话 那是的 呃 我那只觉得你要拿这个model去做什么 对 我们确实发现在有一些task上面 呃 这个数据的quality还是非常重要的 其实在palm里面 呃 我们应该有写过就是我们pre-training corpus的那个selection 就我们会倾向于首先include一些high quality的那个data 比如说wikipedia book corpus这些都是high quality的 我们会 呃 尽量的把所有的data都include进去 然后其次比如说是web document的话 呃 你如果像网上的那个document 那它的质量就会 它们的质量就会比较参差不齐 这样子的话 呃 我们会根据比如说document它本身的quality去sample 就比如说高质量的高quality的document 我们可以会sample的多一点 然后低quality的document的话 我们可能会sample的少一点 我们palm的pre-training corpus大概是这样决定的 对 嗯 对 但这个事情quality好与坏这个很难说 比如说有些model 你比如说想让它在一些比如说composition这种呃ability上面performance特别好 的话 那你不得不include一些compositional的data 但compositional data比如说你只能从reddit或者一些别的地方过来 然后这些quality可能呃 就质量有些时候很难保证 所以呃 也不是说你想要high quality的data在某个domain上就一定能拿到high quality的 所以呃 high quality当然非常重要 但是也有时候我觉得是网上数据呃 数量也是有限 也不是有就是我们可以随便控制的 我可以我可以插一句讲那个data quality这块 但是我我不能提供这个呃语言上面language languagemodel上面的这个这个一些insight 但是我可以提供一些呃cv上insight 就如果你的task是计算机视觉的话 呃 它的那个它的质量跟质量数据质量在我们看来就是尤其在做产品的人 看来是远远重要性是远远超过这个呃 这个模型本身的 尤其在我之前在landing的时候 呃 我们大概我们在做这个就是在做那个manufacturing这个行业嘛 给他们做sars 然后做分类模型和分割模型 嗯 做任何的task我们使用 我们几乎使用过市面上呃 所有的主流模型 甚至我们还会使用一些sota的模型 就比如说我们刚开始做的时候是2018年2018年的cvpr 我们甚至把整个cvpr全部都扫了一遍 大部分的引用次数高的模型全都用了一遍 然后我们在然后再做了一些 这做了很多关于不同模型同样数据的对比 以及呃 同一个模型不同数据的对比 以及不同模型和不同数据的对比 那最后的结论就是数据本身的质量 以及数据的标注的质量都对这个呃 最后的结果产生了决定性的作用 所以那个时候嗯 2019年嘛 应该是2019年年初的时候吧 就吴老师写了一篇文章叫做data centric ai 嘛 当时我们写那篇文章的最大的原因就是在于呃 这个data 它是我们觉得data是非常重要的 尤其是在这个这个language还好一点 我们觉得我们那个时候一直觉得language的做语言模型的人很幸福 你直接上你直接往下载就行了 呃 我们要我们要拿到 比如说我在那个我们去做那个有一个客人客户是韩国的呃 车厂 韩国的车厂 我们给他做这个质量检测的这个分类模型 呃 我们可能要我们拿到一个类型的模型 图片拿拿到五张一个类型图片 可能要在这个生产线上等上一两个月的时间 才能拿到五张这个类别的 那你出来的话 嗯 我们的模型出来一开始我们想到说 哦 他有一个这个他的分类模型里有个类别 我们没有任何的任何相关的数据怎么办呢 嗯 当时就说那我们用zero sharp 这种效果根本就不行 完全过不了他那个过不了他的测试 后来大家就想别的办法 就想到说我们使用当时刚刚18年吧 就那我们使用干吧 我们干两个这个这个生成的图片出来 就生成出来图片 那个模型训练是很难收敛的 收敛出来的这个图片又不够不够真实 所以最终你就只能等待真实的数据 这个给我们了很大很大的困扰 所以我们才会认为呃这个数据是很重要的 但是呃 同时我们看这个gpt就像我刚才问这个问题一样 就是我们看gpt2和gpt3的这个 这个这个变化他们之间的这个性能的变化 虽然我同意学制的观点就是说呃你这个income 你那个income test论理可能是一个很重要的东西 虽然我没有太读懂 但是我那真的给我最有共鸣的就是那个他的那个fine tune task里面有了除了zero sharp以外 有了one shot和这个呃和这个呃这个few shot 那那个我看到他们大部分的这个呃 在那个apple to apple comparison里面 大部分的那个zero shot的这个 这个这个task的准确率在30左右 但是one shot的平均值居然达到了40多 这一下子就是30%到50%的这个提升 就一张图不是一张图 sorry 就一个数据点你就达到了30%到50%的这个这个提升 我觉得这一点也 也呃这一点也算是呃 怎么说呢 也算是一个信号 算是一个信号吧 说明这个数据是很重要的 如果以后每一个领域就每个领域 其实你要去change都只需要非常少的这个这个数据的话 那是不是以后就是build一个 呃就是要要去做一个非常具体场景的这个模型 其实它的这个成本其实越来越低了 呃这个我有可能的呃 我觉得模型本身应该应该是同呃就通用模型 实际上呃到后到最后通用不同的通用模型 它在同样的特别特别高的质量的数据面前 他们的表现很有可能是类似的 嗯我打个比方就是我们原来做在在制造业上 做那个分类的时候 嗯一开始就用一开始就用resnet嘛 因为这个resnet是 呃resnet是图片 当时是图片分类里面最对通用的这个程序 那个那个那个那个网络 那我们后来发现一开始resnet的那个呃分类的这个这个水平是不好的 没有达到我们客户的要求 但我们客户要求也很高了 可能99%以上的这个accuracy 就f1f1f1score非常高 不是像这种什么60%啊50%这种是非常非常高的 那非常非常高 我们开始觉得是不是有一个什么特殊的模型可以达到它呢 所以我们试了很多 跟resnet类似 但是又跟它不一样的模型 像你像像unet呀像mobonet这些的或者什么retina 所有的所有的这些模型我们都试过一遍 但是我们发现哎可能有高有低 但是大家都在一个水平线上 直到有一天我们拿到了标注质量特别高的数据 boom一下你一train 你发现所有的模型他们的准确率都上升一个台阶 大家都挺厉害的 那最后我们发现最后我们就问自己说那是模型厉害呢还是数据厉害 就我们的结论就是还是数据很厉害 所以我们最后就提出来了两个 吴老师提出两个概念 一个是data-centric AI 第二个是small data ML 我觉得他所说的small data并不是说我们不需要特别多的数据 而是说第一 我们的数据要质量特别高 第二就是我们的数据需要平衡 也就是说 其实跟那个tokenization就LOM里面tokenization是类似的 你如果能在一个高位空间去 去做很好的 对一些有意思的重要的feature 做这个很好的数学表述的话 那其实 只要这个数学表述是存在的 那我们的数据的质量也是如果好的 那你就能看到 你一定能看到这个feature 你能看到这个feature你的所有的这个相关的 这个vision上面的task应该都是质量会很高的 对 如果从生成模型角度上来说的话 其实 我们现在的经验是一开始的pre-train阶段能看到的数据量 以及它的丰富程度是非常非常非常重要的 量可能会比 对于我们来说量 第一阶段量会比质量更重要 当然会需要满足一点最基础的要求 比如说文本和图片需要对齐 这一部分的质量是需要求高的 但比如说对于图片 本身的质量 我们指的质量是美学的质量 或者说它的图片这个 有一个图片质量评分的一个系统 就是它的这个清晰度啊等等 这一部分不需要特别的高 在pre-train的阶段 但需要尽量的多 这样能够给language model 这个可以给我们的 这个生成图片生成模型里面负责semantic 负责language那一部分更多更多的输入 然后在这样生成的一个基础模型 我们再对它进行funtune funtune的时候切换成美学评分高的质量 评分高的数据集量可以小很多 通过这样的一个方法能够让它在能够生成更多的内容 同时然后对语义理解更好的同时 生成的质量也更高一些 然后包括对一些specific domain 比如大家现在看到的一些像dreambooth这样的应用 或者说是一些其他的funtune这类的应用 基于一个我们已经训练好的通用大模通用的这个图像生成模型 想要扭转到某一个领域里面 其实需要的时间是非常短的 现在比较先比较好的方法可能几十分钟 去做一个在一个消费级GP上继续用上去做funtune 就可以把一个通用的图像生成模型扭转到扭转成一个domain specific图像生成模型 前提是没有给它植入新的概念 如果要植入新的概念需要时间更长一些 可能需要几个小时 我概念比较多 比较细节的话可能需要几天 但这都是消费级GPU能做的事情 从这个角度上来说 图片生成模型需要一个极大的图文对 这一个图文对的图片文本对齐需要好 但图片质量本身不需要太高 其实我们说图片文本对齐质量高也不需要特别的高 像clip这篇文章的贡献很大一部分就是说 这种比较稍微loose的这种对齐的文本对 也可以训练出很好的文本图片的这样对齐的模型 然后再就是在domain specific以及我们最终训练高质量模型的时候 数据质量对于后面的部分是非常非常重要的 我们刚才聊了很多这个large-length model的话题 正好就跟一周聊到大家也非常关注的 stability AI就是生成式图片 我想很多人相信都已经知道stable diffusion 还有stability AI 但是对于有些可能还不那么熟悉的朋友 我想请一周可以给大家简单做一个介绍 它背后大致的一个原理是怎么样的 好两个问题一个stable diffusion到底是什么 stable diffusion刚才大家聊的时候提到 它是一个denoising的一个模型 但是它不完全是 它是一个big guide它是一个有condition的denoising 它是一个能够前面会有一个小的语言模型 我们叫encoder text encoder 然后text encoder负责把文本转化成计算机能够理解的 一堆embeddings或者说我们叫hidden state 就语言模型里面的hidden state 然后我们把这个文本encoder成计算机能够理解的 这些语言的embeddings以后呢 我们把它fit到一个unet里面 这个unet负责的是基于这个文本完成一系列的降噪过程 就从噪声中每一步根据文本生成相对噪音比较低的图片 然后再一级一级一级这样的去把它生成出一个完整的图片 但这个图片目前还不是人眼可以理解的 目前是一个就在计算机中的表示 然后我们还有一个VAE在后面 通过这个VAE再把这个计算机表示的这个图片 解一把成人能够理解的就是RGB图片 就是正常的一个完整的图片 简而言之就是给一段文本经过几秒钟的时间 它可以生成一个跟你的文本描述尽量相似的一个图 那它跟之前的一些大家看到的像之前有Latent Diffusion Clip Guided Diffusion 然后Condition在这个文本Vector上的和Condition在这个Clip上面的一些生成模型有什么区别 但在之前其实大家还有一个大家印象比较深的应该还有这个DRAE DRAE-DRAE2这个系列模型 那三个区别一个是它开源 开源的意思是我给你一个