你看苹果其实是不太会做游戏的 但是你会发现 如果你就我正好有一批做游戏的朋友 在几年前吧 我就没有最新的数据了 在几年前的话 我得到的信息是说 一个游戏的一个游戏的制作室 一个game studio它一套它一套代码可以几乎把所有的这个 最新的七八个这个这个iOS设备全部覆盖到 然后就就不需要完全不需要重复开发 然后它在上面的收入却远远高于安卓 安卓是每个设备都要重新开发 所以你从这两个角度来说 那我们要问如果那我就要问了 如果今天 这个openai你要去host一个所谓的操作系统 对吧 那你你给你给开发者提供了什么样价值 你给他的这个 revenue在哪里 你给他的这个developer speed在哪里 这个我感觉openai没有任何的思考 所以我觉得没有办法去判断说它是否能做出 类似于操作系统这样的ecosystem 我也比较同意这一点 就我们没有办法拿一个大模型来解决所有的问题 就就算是我们说以后language model大一统 GP4 GP5 能够走到一个真的非常非常贴近于AGI的这种 文本交互的一个体验 那但但它离 生产环境还是远的 因为生生我们生产环境需要的东西不是一个一个 不是一个语言模型 我们需要的是一个能够一整套体系从产品设计到产品到这个 跟用户的交互到后面需要跟上的人工的服务到到整体的如果是电商的服务 或者是电商产品或者其他的牵扯供应链产品的供应链到后面等等 我们很难说以一个模型来称这件事这些事情 那虽然模型在里面可能会在一个非常重要的一个部分啊 嗯 非得用meta for的话 我我感觉这这相比于一个底层的操作系统 它可能更像是一个 嗯 平台的一个提供提供商有点像一个甚至是甚至有可能像一个consultancy的感觉 去去给带去给不同的行业不同的产品解决这部分问题 他呃产品对他的依赖不在于他的平台的能力 他也很难hold住整个入口 从提供能力的这部分 我不怀疑他可能会被植入到非常非常多的产品里面 对我我我想打个比方哈 就是说我我自己觉得我自己个人觉得他最可能的是成为pass服务的一部分 pass里面的instance的一部分 比如说aws吧 那aws里面 aws里面有一种类型的AI的客户叫call center 对吧 你电话打进来 电话打进来以后你你比如你今天去打电话 中国可能都是会有很多人工在美国基本上没有人 你打进去以后他就会有很多人工在美国 基本上没有人 你打进去以后他就会有电话提示说 哎 你你要你要问什么呀 这其实里面就有这个 其实这里面就是ASR加上NLP吧 那ASR加上NLP的话 呃 你的你的backend 今天的backend怎么做的呢 肯定是是EC2 serve了 是EC2 serve了 比如说打个比方 serve了BERT 然后又serve了一个什么conformer model打个比方哈 那那你在看对于开发者对开发这个call center application的这个开发者来说 他需要去配置这个 他需要去配置正确的BERT的version 对吧 然后再配置正确的EC2 instance 你是要8个AMD 你还是要Narutong 你还是要NVIDIA 这是才是问题的最关键的地方 当然如果我能看到就是说如果我们能做出一个 呃 通用的像GBT这样通用的language model 他他可以统一这所有的这些这些这里面的这些这些任务 他可以把ASR和这个NLP 还有其他一堆所有的这些任务都给统一了 你就一个模型就serve了 那在这个时候我就不需要去让开发者来配置了 我就直接我我我AWS可以直接往上面搁一个开源版的 比如说GBT NeoX打个比方啊 然后你都不需要选 你就不需要选EC2了 你不需要配置EC2了 你直接配置这个模型上去就好了 他就能给你那这样的话 开发者的开发速度得到提升 他的成本也可能得到降低 因为在这个时候你把它抽象出来了以后 你把这API抽象出来了以后 你下面你下面的硬件怎么选择呢 肯定是哪种硬件便宜 这个时候你可以有你自己的objective 你可能要QoS去优化QoS 你可能要优化你的cost 对吧 那他自动就给你优化了 那这个时候他可能就会成为pass服务的一部分 我觉得这个是很有价值的 所以说这个OpenAI自己做不成 但是他有了他有了一个渠道叫做这个Microsoft 对我们最近看到这个 我最近有一次正好那个AWS的这个reinvent大会上 我看到这个AWS跟Stability AI也有很紧密的这个这个合作嘛 然后最近其实Microsoft跟这个OpenAI的一个deal 也是引起了大家的这个注意 应该是几年前 Microsoft就已经这个 在OpenAI上投资了这个一个billion 就11亿美金 然后最近好像看到他们应该是在准备去sign 就是一个10 billion 100亿美金的一个OpenAI的这个这个融资 该加起来这个11个billion的这个dollar的 这个这个这个投资拿回来之前 他可以分到OpenAI75%的这个这个这个profit 我们这样有个经典的一个说法 就是说这个创业公司跟这个传统巨头的这个 呃比拼就在于这个传就在于这个传统巨头 这个去innovate自己之前就创实现创新之前 这个startup能不能够解决好他自己这个distribution 这个渠道的这个这个这个问题 比方上一波AI我们没有看到任何说一个 呃用AI来做 比如说这个drug discovery这个药物 这个药物研发的公司好像没有 好像没有看到有什么成功的长出来 但是我们现在看到的是几乎所有的这个 做药物研发的传统公司其实都已经在开始 多少应用上了一个呃这个这个AI 所以我觉得一个对一个这个一个这个AI的 这个创业公司要要接下来要怎么去就是随着 这个技术这个演进啊去做出他的这个呃这个 所谓这个mode和护城河 我觉得还是一个挺挺这个挺值得关注的 一个一个事情啊 嗯 哎那正好刚才其实我们讲了很多就是business model的事情那what's next就下一步到底是什么 就我个人的感觉是这个这个下一步其实里边 其实有两个方面就是一个是更偏science 更偏研究这一块可能另外一方面就是更偏 这个engineering这一块那我们稍微超拆开来 说这个从研究这个层面来说我们现在的这一些 尝试他还有哪一些这个limitation他通过 基于现在这个这个这个fundamental的这种 逻辑的这一些可能一些调一些优化和微调 给大家怎么样的一个天花板要不这个雪芝 听你来聊一聊 嗯好对因为我个人的研究方向是偏natural language reasoning的啊然后我们其实去年一年的 研究也表明就现在large language model虽然他在 很多呃NLP的task上面performance非常好但是 你如果给他一些更加challenge的task 他的performance还是不够令人满意的比如说像 reasoning这种比较复杂的task就我们当时说 这个东西其实有type 1跟type 2type 1就是说 有一些task你是需要fast thinking就是我问你 这个问题你立马就能答出答案这些task上面 来large language model已经做得很好了然后另外一边 就是type 2type 2就是说我平时问你一个问题 比如我问你一个数学问题或问你一个 微积分问题你可能要想很久或者你要就是 很清楚的逻辑思考就把这个结果给推出来 像这种问题的话现在large language model做得 还是比较差的所以在很多的这些更加challenge 或者更加complex的这种task上面large language model 还是有提升空间的这也就是我之前说为什么 这个现在还是有scale up的这个空间因为我们 现在并不知道limit在哪就是在很多task上 large language model还是我们觉得还是有提升的空间的 对然后另外一边的话我觉得large language model 在有一些东西上面比如说像tragibity其实 有很多人就是你看推特上的thread或者有人 发blog post就是做了一些研究也发现比如说 tragibity它的factuality其实并不是特别好 等于说比如说你问他一些问题他会给你一个 非常看上去非常令人信服的答案但是有时候 这个答案可能是胡编乱造的就是他背后 并没有真的证据支持比如说你作为一个人类 你看这个答案你就知道有里面有一些逻辑 可能是错的或者里面有一些事实是胡编乱造的 对然后这个可能也是一个将来需要提升的东西 然后还有一个是safety方面safety方面就是说 你如何保证这些generative出来的东西是安全的 然后他不会对比如说任何一个种族产生bias 这也是一个比较重要的方面因为现在你想 这些large language model也好或者vision large vision models也好就生成的model也好就他们生成的东西 完全是根据就是他们的最后生成的东西是根据 training的那个distribution来的然后你可以想见在 现在的这个世界上这个training distribution 本身是带有一定的bias的所以相应而来的就是 这些model也自然会在生成过程中带着这些bias 所以如何保证比如说这些model将来生成的东西 是安全的然后他不会比如说implicitly对某一些 人或者某一些东西产生bias这也是非常重要的 对不然的话你想有些人用他的时候就会觉得 这个结果对自己并不是很好对 对我好奇但是雪芝你前面提到的那前面提到 那两点就是对于现在这个模型还比较有challenge 你觉得说是现在我们通过一些一些可以说是 微调它可以实现还是说我们可能需要下一个 类似于transformer或者说这种attention model 这一些比较fundamental的这个breakthrough才能够去解决的呢 这是个很好的问题对其实我们去年其实发了 蛮多paper在研究这个topic我觉得这个是同样就 同时需要两方面的努力的一方面是在fundamental 这个model上面还是需要一定的breakthrough的 然后另外一边是说在fundamental这个model之上 我们如何用一些更好的更novel的technique 能够unlock这些model在这些事情上的一些capability 就首先的fundational model那边我们发现scale 就model的scale还是非常重要的比如说你拿一些 小的model你在上面叠再多的fancy的technique 其实有些时候就是还是解决不了那些非常难的task 所以fundational model的scalefundational model 本身的capability是非常重要的 这个是scale那一方面可以解决的 然后另外一方面的话就是说如果你在上面 再apply一些novel的technique 其实我们去年写了一些paper就是比如说 我之前提到的比如train of thought 就是一个可以unlock model reasoning的一个方法 就是如果没有train of thought的话 即使是再好的model我们当时试了一个 数学reasoning task 这个数学reasoning也不是特别难 大概是初中数学题的样子 对我们当时比如说用PALM540B的那个model 比如540B你觉得它size已经很大了对吧 但是如果你直接做future learning的话 它的performance其实大概只有20%不到的accuracy的样子 就是它只能做到1%的问题 但是用了我们那个train of thought 那个novel的technique 就是是一个更复杂的prompting的方法 我们就可以把这个performance提到 大概60%的accuracy 所以从20%到60%还是区别非常大的 所以一边是fundational model的本身的能力 然后另外一边是你如何在上面做一些 更加novel的这个时候researcher research scientist的将来能研发出更好的technique 可能unlock这些能力或者elicit出这种 对我很赞同雪芝说的这几个方面 尤其是今天的那个Chair GPT 它对那个facts的这个临近也是很有限的 就是吴老师写过一个很有意思的prompt 看那个Chair GPT他说为什么5比10大 然后Chair GPT就给你给你写上200字 告诉你给你论证一下为什么5比10大 然后我们我们自己我们会发现就很多facts 他都不太清楚 还有一个很有意思的地方就是对文献的 文献的这个引用 因为看起来Chair GPT它是 我读了paper以后看起来就是说 它的training set应该是从跟这个 都是在网上crawl来的嘛 然后有网上也有也有为几百颗这样的高质量数据 也有reality里面这种很复杂的数据 所以所以比如说有一个很有意思的例子 就是他对那个他在中文的Chair GPT 他对唐诗的理解是很糟糕的 就是你他你这个你会发现他连唐诗三班首都没有背过 你你比如说我去找了一个非不是最好的 这个诗人比如说我引用了李商隐的诗 他跟我说这是杜甫的 然后说这是杜甫哪首诗 你会发现杜甫根本没写过那首诗 那首诗的名字和诗都是他自己编的 所以他在facts上面是有问题的 然后还有但是我不知道 GPT-4会不会在这个上面有一些解决的方案 这个这个可能是拭目以待 然后另外一个方面就是他在对话上是不行的 他不太能够去理解这个提问者的这个这个问题 那并且我我看他的那个论文上面 GPT-3和Chart GPT-3的一些介绍来说的话 他引入了很少量的这个这个单轮次对话的这个这个数据 所以他当你他如果你问他一个问题 你对他的回答不满意 你说比如说我今天问他说 我明天要去纽约 你告诉我纽约最好的中餐馆是哪一家 他会给你一个他会给你一个没有太 没有太有帮助的这个这个回答 那个时候你再去追问的时候 你会发现他完全找不到主题了 那这个问题其实我知道他已经开始做一些 GPT-4肯定在做一些补救 那他的补救直接补救的方法就是 他最近那个GPT-3好像OpenAI出了一个GPT-3的这个 GPT-3的一个软件叫做GPT-4的一个软件 那这个软件他就是用这个软件来去 他用这个软件来去做一些补救 然后他就会把这个软件给你 你就可以直接用这个软件来去补救 你就可以直接用这个软件来去补救 然后你就可以直接用这个软件来去补救 那这个软件他就会给你