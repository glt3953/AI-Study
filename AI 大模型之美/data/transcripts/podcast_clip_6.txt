这个chatbot的这个这个这个Ls的应用 我去我去test flight里面申请好像没申请到 但是你如果有装上这个应用以后呢 你可以 你就会出现一个像iMessage或者微信那样的对话框 你可以不停的和这个ChatGPT聊天 当你不停的和他聊天的时候 在这个手机里面他就会一直他会告诉你 我会要收集你的信息 那这个时候你会和他 生成很多很多的这个对话信息 那在这个情况下他可能会拿到很多这样的 当然你在这个网页版上面也可以得到很多对话信息 他会 他一定会把这些对话的这个信息数据拿去做训练 然后这个这个有可能啊 我觉得是有可能 提高他多轮次对话的这个这个这个这个性能 但是我不知道他自己 GPT-3的这个架构设计里面 他是不是能够把这些contact都都学到 这件事情我不知道 但是我希望他能够再把多轮对话的contact学的更 更透彻一些 我这边还有一个关于打模型能力提升的问题 请教一下徐知和各位嘉宾啊 一方面就是关于文本的这个 模型的这个能力 刚才一文也提到现在ChatGPT对于中文的文本的生成还是有非常多的问题 那这样的问题能不能够之后通过工程上训练更多的相关的数据就能够得到比较好的这个解决呀 然后第二点就是我也听到 很多Foundation model通过训练Github上的代码数据 还是很明显的提升了对于这个自然语言的这个推理能力 我想这也是模型迁移学习的一部分 我不知道这个论断是不是否是对的 以及未来的话当大模型其实学到更多的多模态的数据之后 能不能够对其他的modality的能力项也有明显的提升 对 这是个很好的问题 首先第一个问题你说如果中文 中文这个是multilingual的问题 我不太确定GPT3或者ChatGPT在pre-training corpus里面中文占的比例是多少 但是根据现在大模型的所有pre-training distribution来看 英文首先肯定是主要的就占主要部分的一个pre-training的部分 然后其他语言的话基本上是占比较小的比例的 所以我猜中文在里面占的比例应该比较少 如果你想让就是ChatGPT在中文上面能力更好的话 或者任何其他大模型中文或者其他语言能力更好的话 你可以让它见到更多就提升那个corpus的比例 然后pre-training的时间可以更长一点 让它在那个corpus上面能adapt更好一点 对 然后关于那个其他模态的问题 你这是个很好的问题 首先code代码数据的训练是不是能帮助提升reasoning 这个答案是肯定的 对 因为我们做过很多实验 就是其实GPT就ChatGPT它的那个base model 其实是那个GPT3.5那个model 然后那个GPT3.5它其实是有两个version的 一个是那个text version 一个是code version 就它们有个叫text advanced的东西 也有个叫code advanced的东西 然后code advanced是另外在code data上面在train过的 然后我们当时比过那两个model的那个 在reasoning上面的performance 我们发现在code上面train过的那个model reasoning的performance要比那个 只在text上面train的那个model要好很多 所以code代码数据训练肯定是能帮助reasoning能力的 然后我们当时看了一下 大概是因为GitHub上面的很多code 它其实提升了某些方面的能力 然后code它其实提升了model在就是manipulate symbolic的能力 因为code你可以想象成是很多那个 就是symbol的一个 一个你在操控那些symbol 然后你需要就是很清晰的逻辑 把那些symbol操控好 这样才能得出最后那个正确的答案对吧 所以这个code的training的训练 是对它提升reasoning能力很有帮助的 这个是原因对 然后未来如果加其他新的模态的数据的话 我觉得这个model是可以提升其他模态能力的 就比如说其实已经deepmind 已经有篇paper叫flamingo 对flamingo里面其实有多模态 它既有vision data也有text data 然后它把vision跟text datainterleave起来 然后就问问题的时候 它会给你个图片 然后问你就它可以回答 比如说这个图片是哪个城市 然后它可以reason说 哦这个图片里面比如有很多车或者很多高楼 它有可能是纽约或者什么 就是它它其实是在 你在training过程中加多模态的时候 你是能让这个model有多模态的能力的 然后这个其实也是用于其他模态 比如说像robotics或者别的东西 就是你在training当中如果能加的话 就是model是同时可以有多模态能力的 然后还有你最后一个问题 说这些模态是否会相互帮助 我觉得是很有可能的 你想人在学习的时候不可能 你从小到大只是对着text学对吧 你在学text的时候同时也看到了很多 比如说image video然后audio之类的 然后这些模态互相之间肯定是有interaction的 你如果能在model training当中加 把这些模态都加进去 然后让他们interaction能够最大化的话 其实是能够让这些模态互相进行帮助 让model就整体的能力得到更大的提升的 这个也是我觉得现在很promising的一个方向 然后很多公司其实也都在研究这个 对 这个其实就引申出了一个很重要的一个对未来的预期 比如说开源的模型其实它在文生图效果很好 大家也用的这个数量其实比达利要多的 但是会不会未来几年就是这些大厂的币源模型 他们因为训练了更多这个维度的这个数据 然后他们有更大的参数 所以他们可能在长线上反而在某个特定领域 还是会比这个开源模型效果好 就这个我不知道这个你会怎么看 我觉得开源模型也可以引入多模态 然后确认时间更长 我不觉得这件事情是互相排斥的 图片生成的这一块 你现在看到还有什么你觉得可能的限制和未来的 一个主攻的会提升的方向 就从图片来说 我们能我们对模型的自己的能力限制 现在还是有一个比较明确的理解的 像说我打一个比方 我经常打这个比方说我们抓一个化石出来 我想给他沟通清楚说一个假方向要沟通清楚 说我想把什么东西画出来 要经过几轮交互要花多少时间 然后你只用77个token 只用77个单词想就给模型描述出清楚这个现实 当然是不是那么现实的 对吧 沟通的bandwidth是不够的 那怎么提升我们跟模型沟通的 其实是一个比较是一个low-hung foot 就比较容易去解决的一个问题 就需要不同的模型 然后不同的condition的方式 但这不能说是很多很明确的research progress 因为这个怎么做大家是清楚的 只是需要花一些时间 有一些knowhow的问题可能需要去解决 那嗯这是一个短要明确的短期的一个方向 那长期来看 呃图片模型我刚才提到了有一点非常好啊 我也我也我也非常相信这件事情是 在多模态这件事情上面 我们现在的图片模型上面用的这个语言能力 其实是非常低的 呃低到什么程度呢 我们的语言我们的语言模型几百m 一个币多一点 那跟我们上百币动辄上百币的现在真正的大模型 大语言模型来说 呃其实差的非常非常的多 那提升模型的语言能力也已经被验证了 说是一个让模型生成能力提升的非常好的一个方法 但我们好像看到了一个threshold 就是有这提升到某一个领域 某一个瓶颈之后再往上可能就会比较难 那怎么能让呃模型的语言能力变得更强 乃至这种多模特的方式去做这个图片的生成 效果变得更好 这也是一个方向 但这是图片部分啊 往后说的话 其实扩展模材是比较重要的一件事情 嗯像呃比较大短期的视频模型 3D模型应该都是会在2013年呃2023年会发生的事情 呃2023年大家会看到一些基础的呃 视频和3D模型出来 然后有一些应该也会被开源 那这一部分希望能从这个领域去看说 呃怎么去推进呃更多应用场景的探索 对嗯 Sam Altman其实也很多次的提到这个接下来这个多模特 应该是他们这个发展的这个主攻的这个方向啊 所以这个可能对很多对这个快排不是很熟悉的 这个朋友来说 我想呃可以麻烦雪芝给大家呃大家简单的介绍一下 这个多模态为什么认为它对于这个进一步的提升啊那么重要 首先它为什么重要 我觉得是类比人类的学习吧 就首先现在单模态是比较这些models是比较容易train的 比如说Language model的话 你呃或者你只train一个language model 或者只train一个vision model 那它的input非常的固定 然后你可以用一个呃同样的encoder去encode所有的信息 就呃因为它的input output是一致的 对 如果多模态的话 可能最大的难点就是你怎么把就是不同的模态align起来 然后能够让他们之间的interaction最大化 对 然后我之所以觉得这个东西非常promising 是就是我刚说的类比于人类的学习方法 对吧 假设你作为比如说你小孩子的时候 你如果只读书的话 你学到的知识是有限的 但是如果你同时见到了image或者audio或者是video的话 那你其实是这些模态之间是互相可以有interaction的 比如说你读书 你比如说呃想做一些space上 spatial上面的reasoning 比如说你想你向前走了五步 你再向右走了五步 你现在在哪个方向 对吧 你你读书的话 在这些在这些东西在你看来它只是一些text 你其实没有你如果没有你如果没有眼睛的话 你是不知道这个东西具体对应的是什么 但是你同时如果看到了图片 或者你在就是你真的移动过的话 那你知道这个text其实它对应的 比如说是图片上的一个就是向前向右的 这个一个斜方向的是这样的一个东西 对吧 所以你如果呃在这些模态之间 如果互相能学到一些交互的东西的话 它是能互相augment就是互相提高你对每一个模态的理解能力的 对 我觉得这个事情非常重要 因为我觉得这个将来可以unlock很多很多别的ability 比如说self-driving self-driving 你其实比如说你单你用一个language model 能解或者单用一个vision model 能解决就是self-driving里面的很多问题吗 应该很难 对吧 你想你你人之所以比如说能开车开的这么好 是因为你在多年的experience之间 呃呃中间你学会了 比如说这个symbol对应着什么 然后比如说这个词对应着什么 这里面你看到的东西是什么 然后你你从这些多模态的交互当中 你学到了一些东西 然后你才能推理 然后你才能更好地进行应对 所以我这才是我为什么觉得就是 然后其实很多公司现在也在往这个方向发展 就是说如何能引进多模态 其实单模态大家其实现在这条路已经 走的差不多到limit了 都大家都已经scale up到差不多 呃就是到头了的阶段 你可以在网上scale up一点点 但是大家都差不多知道你scale到这个程度 大概现在performance是什么样 然后单模态其实已经差不多就是研究到一个 呃bottleneck的阶段 然后其实他们就很多人其实都觉得下一个 呃promising的方向 是把多模态结合在一起 然后你互相就是让这些多模态互相之间 能够interact 然后能够maximize 他最后学到的东西就是你这个人对于这个 世界的整体把握的这个能力对 那现在我们看到我们要真正去做好这个多 模态的难点主要核心的难点在哪呢 你单模态的话其实你只要一个encoder就够了 对吧你text有个text encoder 或者vision有个vision encoder 然后它的所有input都是一致的 你用同一个tokenization同一个encoder 你就可以encoder出来一个unified representation 但是如果多模态的话这个非常tricky 因为text它会经过一个text encoder 变成一个representation video呃image image会经过一个image encoder 变成一个image representation对吧 然后你这之间就是这个东西怎么align在一起 然后怎么互相让他们呃就是interact 然后interaction能够maximize 这些都是非常难的 对之前那个flamingo paper 他们用了一个比较好的方法就是interleave 就是把text跟image互相插在就是互相插在一起 对比如一个image下面跟着一个text 一个text后面再跟着一个image image后面再跟着一个text 对然后他是先把image通过一个image encoder encoder到呃一个representation 然后再用一个language model 去把那个text encoder到另外一个呃text的space 然后通过这种interleave的方式去train这个model 然后最后让那个model能够生成一个reasonable text 这样子对所以你怎么把这些互相呃多个 multi unified在一起变成一个就是 这个就整个model的training到底objective是什么 然后你怎么把这些多模特结合在一起 就变成一个unified representation 然后以及让他们 multi跟multi之间的interaction最大化 就是让他们互相能真的产生作用 不然的话你就是在单纯一个text model 跟单纯一个vision model对吧 所以你要把他们互相interact到最大化 这个是我觉得是个比较大比较难的部分 对而且更不用说video了 video的话处理起来更麻烦 你可以想象成比如video的话 它可以割成一帧一帧 然后每一帧的话 它分别可以有image也可以有text对吧 你比如把trans把它transcript搞下来的话 它就另外有个text 然后你要把这些东西都align在一起 然后你怎么处理帧跟帧之间的关系 然后怎么又跟另外的text 比如说这个video有个title 然后这个video有个audio 就怎么把这些东西全align在一起 就是个比较大的难点 刚刚我们讲到就是当我们想到这个 next step是什么的时候 一方面是我们刚刚讨论的 就是science 就是research的这个层面需要 需要哪一些提升 那我觉得其实我们也很重视 就是实际落地的这个场景 比如说我怎么去考虑这个inference的成本 要使用这样的一个生成式的model 或者说这个大模型 把它开发成自己想要的应用 我们现在看到从这个工具的角度来说 还有哪一些大家觉得 比较有挑战的这个地方 就是以后像这个 Solidity AI这种 就是提供这个model的这些公司以后 大家会不会把这个 就是我们现在的这个模型 是不是跟上一代这个AI 也许是是否需要一些提升